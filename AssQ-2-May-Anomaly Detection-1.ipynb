{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f7022d7-c6cf-4d24-b752-2a9b2945c05e",
   "metadata": {},
   "source": [
    "# AssQ-2-May-Anomaly Detection-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f740d-472f-42e4-8a53-a0e7c87b2894",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is anomaly detection and what is its purpose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942eabb9-e968-447d-8a60-5c0beab17df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Anomaly detection is the identification of rare events, items, or observations \n",
    "which are suspicious because they differ significantly from standard behaviors or patterns. \n",
    "Anomalies in data are also called standard deviations, outliers, noise, novelties, and exceptions.\n",
    "\n",
    "Anomaly detection identifies suspicious activity that falls outside of your established\n",
    "normal patterns of behavior. A solution protects your system in real-time from instances that could \n",
    "result in significant financial losses, data breaches, and other harmful events.\n",
    "\n",
    "An anomaly is an abnormality, a blip on the screen of life \n",
    "that doesn't fit with the rest of the pattern. If you are a breeder of black dogs and \n",
    "one puppy comes out pink, that puppy is an anomaly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe24db50-cd9b-4e2a-920d-ccc180817cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the key challenges in anomaly detection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8158a9-243b-45a7-8213-f0a632499222",
   "metadata": {},
   "outputs": [],
   "source": [
    "Challenges in anomaly detection include appropriate feature extraction, defining normal behaviors,\n",
    "handling imbalanced distribution of normal and abnormal data, addressing the \n",
    "variations in abnormal behavior, sparse occurrence of abnormal events, environmental variations, camera movements, etc.\n",
    "\n",
    "An anomaly is defined as an observation that does not conform to the expected normal behaviour. \n",
    "To detect anomalies, modelling and encapsulating normal data is still an open problem,\n",
    "especially if only normal (non-anomalous)\n",
    "data is available for training time, making it a challenging problem.\n",
    "\n",
    "The most apparent drawback of anomaly detection is the high false alarm rates.\n",
    "The question is if this is an unsolvable problem that will render anomaly detection useless. \n",
    "Misuse detection means looking for known malicious or unwanted behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717c3cc2-c032-440c-b6b5-9fb3f545faab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ecf5a3-5b07-40bc-a471-1f9339d8c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c9d56-19f1-45ab-897b-0201de115828",
   "metadata": {},
   "outputs": [],
   "source": [
    "Actually in supervised learning, you have the data set labelled (e.g good, bad) \n",
    "and you pass the labelled values as you train the model so that it learns parameters \n",
    "that will separate the 'good' from 'bad' results. In anomaly detection,\n",
    "it is unsupervised as you do not pass any labelled values..\n",
    "\n",
    "Supervised anomaly/outlier detection\n",
    "For supervised anomaly detection, you need labelled training data where for each row you know if \n",
    "it is an outlier/anomaly or not. Any modeling technique for binary responses will work here,\n",
    "e.g. logistic regression or gradient boosting.\n",
    "\n",
    "The typical application is fraud detection.\n",
    "\n",
    "Usually, one does not have labelled data, so one has to rely on unsupervised methods with their usual pros and cons.\n",
    "\n",
    "Unsupervised anomaly/outlier detection\n",
    "We have a \"reference\" training data at hand but unfortunately without knowing which rows are outliers or not.\n",
    "Here, it is tempting to let statistical algorithms do the guess work. Some of the typical approaches are:\n",
    "\n",
    "density based: local outlier factor (LOF), isolation forests.\n",
    "\n",
    "distance based: How far away is a row from the average e.g in terms of Mahalanobis distance?\n",
    "\n",
    "autoencoder: How bad can the row be reconstructed by an autoencoder neural network?\n",
    "\n",
    "model based: model each variable by the others and hunt for high residuals.\n",
    "\n",
    "...\n",
    "\n",
    "Each of the techniques has its pros and cons. There is no approach that does somehow better than the rest\n",
    "for all types of problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c7194c-2443-41e9-a6ae-cbb45d084825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb412a7-92c5-404a-a652-a81710355576",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What are the main categories of anomaly detection algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e64f70e-8423-4863-82e9-64c832a69bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Checklist: 1. Isolation Forest 2. Local Outlier Factor 3. Robust Covariance 4. One-Class SVM 5. One-Class SVM (SGD)\n",
    "Isolation Forest.\n",
    "Local Outlier Factor.\n",
    "Robust Covariance.\n",
    "One-Class SVM.\n",
    "One-Class SVM (SGD)\n",
    "\n",
    "There are three main classes of anomaly detection techniques:\n",
    "    unsupervised, semi-supervised, and supervised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd2e1b-394b-48ab-ad3f-c051e3736720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e81de-4c6d-40bd-ac17-ad711b88225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What are the main assumptions made by distance-based anomaly detection methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81e93ef-31a0-4f6a-af8c-dc38624a870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Distance-based outlier detection method consults the neighbourhood of an object,\n",
    "which is defined by a given radius. An object is then considered an outlier \n",
    "if its neighborhood does not have enough other points. \n",
    "A distance the threshold that can be defined as a reasonable neighbourhood of the object.\n",
    "\n",
    "The basic assumptions for anomaly detection are that the anomalies, or outliers,\n",
    "occur rarely in the data, and they are significantly different from \n",
    "the expected pattern in the context being considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90dd7d2-e4a2-4de2-aaa4-cce3880ee2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83668d85-6cd0-4adb-913a-e457de476aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. How does the LOF algorithm compute anomaly scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd993858-31a4-4ac5-9dd7-c1140e6ced77",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method\n",
    "which computes the local density deviation of a given data point with respect to its neighbors.\n",
    "It considers as outliers the samples that have \n",
    "a substantially lower density than their neighbors.\n",
    "\n",
    "In terms of testing, the trained SG-Model M directly calculates the anomaly scores s given samples x, \n",
    "that is,\n",
    "\n",
    "s = M(x) = S(R(x)).\n",
    "\n",
    "\n",
    "LOF compares the density of any given data point to the density of its neighbors. \n",
    "Since outliers come from low-density areas, the ratio will be higher for anomalous data points.\n",
    "As a rule of thumb, a normal data point has a LOF between 1 and 1.5\n",
    "whereas anomalous observations will have much higher LOF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1207d249-590d-4263-80a5-533581a54e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b10c7c-70dd-4464-a660-1765c01a0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. What are the key parameters of the Isolation Forest algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31602e2c-127a-4d45-aaa4-701c76a45ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Important parameters in Isolation Forest\n",
    "number of trees / estimators : how big is the forest.\n",
    "contamination: the fraction of the dataset that contains abnormal instances, e.g. 0.1 or 10%\n",
    "max samples: The number of samples to draw from the training set to train each Isolation Tree with.\n",
    "\n",
    "The idea behind Isolation Forest is that, on average, outliers will be closer to the root node \n",
    "(i.e. at a lower depth) than normal instances. \n",
    "\n",
    "Isolation Forest is an algorithm for data anomaly detection initially developed by Fei \n",
    "Tony Liu and Zhi-Hua Zhou in 2008. Isolation Forest detects anomalies using binary trees.\n",
    "The algorithm has a linear time complexity and a low memory requirement, \n",
    "which works well with high-volume data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95864c6-906a-467d-b25e-b87ef4b80688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a7c5e2-59d8-41bd-8d48-0454208f2f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41386ac6-a353-43b2-a67f-9809fe97e765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10ecc0e-7cf8-459f-8a95-b26895e0b05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f08ca3-e459-41fa-b888-91583e655aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a52a075-3ff5-424a-94a4-c9c1cd0ac021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
